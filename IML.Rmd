---
title: "Data science beyond Modelling"
output:
  html_document:
    number_sections: false
    fig_caption: true
    toc: true
    fig_width: 9
    fig_height: 6
    theme: united
    highlight: zenburn
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Do Computers Lie?

We have been constantly told this statement "Computers don't lie". Yes in fact Computers don't lie, but neither does it speak the truth. A computer does what its Master programs it to do. Similarly, A model wouldn't lie unless the Machine Learning Engineer doesn't want it to lie. 


### Machine Bias

There was a nice episode of the podcast [You are not so smart](https://youarenotsosmart.com/2017/11/20/yanss-115-how-we-transferred-our-biases-into-our-machines-and-what-we-can-do-about-it/) came out last year. This is an excerpt from it:

*“I want a machine-learning algorithm to learn what tumors looked like in the past, and I want it to become biased toward selecting those kind of tumors in the future,” explains philosopher Shannon Vallor at Santa Clara University.  “But I don’t want a machine-learning algorithm to learn what successful engineers and doctors looked like in the past and then become biased toward selecting those kinds of people when sorting and ranking resumes.”*


### The Problem

Machine Bias can occur due to a lot of factors but a few to name is:

* Biased Training Dataset
* Bias Variable in the Feature Space
* BlackBox Modelling of not understanding what's going on with the Model 

Below is an example of how Google Translate, when translated the following text to a Gender-neutral langauge and back to English - applies its bias (primarily due to the nature of biased Training Dataset)

![img](https://image-store.slidesharecdn.com/3b4968dd-1035-430a-823e-33f10c978343-original.png)

### The Solution

The first step of finding solution to any problem is accepting **The Problem exists**. Let's accept that fact and see how to use Kaggle Survey results and help the community tackle Machine Bias.

### Libraries

```{r, message = FALSE, warning=FALSE}
suppressPackageStartupMessages(library(tidyverse)) 
suppressPackageStartupMessages(library(highcharter))
suppressPackageStartupMessages(library(DataExplorer))
suppressPackageStartupMessages(library(scales))

plotting_missing <- function(df){

  #based on erikbruin's code snippet
    
NAcol <- which(colSums(is.na(df)) > 0)
NAcount <- sort(colSums(sapply(df[NAcol], is.na)), decreasing = TRUE)
NADF <- data.frame(variable=names(NAcount), missing=NAcount)
NADF$PctMissing <- round(((NADF$missing/nrow(df))*100),1)
NADF %>%
    ggplot(aes(x=reorder(variable, PctMissing), y=PctMissing)) +
    geom_bar(stat='identity', fill='red') + coord_flip(y=c(0,110)) +
    labs(x="", y="Percent missing") +
    geom_text(aes(label=paste0(NADF$PctMissing, "%"), hjust=-0.1))
}




```


```{r, message = FALSE, warning=FALSE}
survey <- read_csv("input/multipleChoiceResponses.csv", skip = 1, col_types = cols())

```

### Ignorance is Bliss - but not always! 
  

```{r echo=FALSE, fig.show = 'hide'}

survey %>%  select(contains("How do you perceive the importance of the following topics?"),
                   contains("Does your current employer incorporate machine learning methods into their business?"),
                   starts_with("In which country"),
                   contains("compensation")
) %>% 
#plot_missing() -> p1 
  plotting_missing() -> p1

```

```{r}
p1 + theme(axis.text = element_text(size = 6)) + labs(title = "Ignorance beyond DS")

```



The above plot is to demonstrate how much these questions that are about Model Fairness / Bias, have been ignored. 

While asking about **Salary made 15% of respondents** to not answer, Questions about **Reproducibility, Explainability and Bias made 37% of respondents** to skip answering. The salary question comparsion is here to show relatively worse questions like this are approached. 


### Reproducibility, Explainability and Bias


```{r warning = FALSE}
survey %>% select(contains("How do you perceive the importance of the following topics?")) %>% 
  gather() %>% 
  mutate(key = str_replace(key,"-","\n")) %>% 
  mutate(key = str_replace(key,"How do you perceive the importance of the following topics?",""),
         key = str_replace(key, regex("\\?"),""), 
         key = str_replace(key, regex("\\-|\\:"),"")) %>% 
  group_by(key) %>% 
  count(value) %>% 
  drop_na() %>% 
  mutate(n = n / sum(n)) %>% 
  ggplot() + geom_col(aes(value,n, fill = key, ), stat = "identity", show.legend = FALSE) +
   geom_label(aes(x = value, y = n - 0.05, label = percent(n)),
            hjust=0, vjust=0, size = 4, colour = 'black',
            fontface = 'bold') +
  facet_wrap(~key) +
  scale_y_continuous(labels = percent_format()) +
  theme_minimal() +
  theme(axis.text = element_text(angle = 45, size = 6)) +
  labs(title = "Perception on Reproducibility, Explainability and Model Bias ")
```

 
```{r}
survey %>% select(contains("How do you perceive the importance of the following topics?")) %>% 
  gather() %>% 
  mutate(key = str_replace(key,"How do you perceive the importance of the following topics?",""),
         key = str_replace(key, regex("\\?"),""), 
         key = str_replace(key, regex("\\-"),"")) %>% 
  group_by(key) %>% 
  count(value) %>% 
  mutate(n = percent(n / sum(n)))  %>% 
  spread(value,n) %>% 
  knitr::kable()
```


### WIP 

Please share your appreciation through upvote, More importantly comments to improve this Kernel!